{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1733977148274,"sparkVersion":"3.5.1","uid":"Tokenizer_100c3426467e","paramMap":{"outputCol":"tokens","inputCol":"Text"},"defaultParamMap":{"outputCol":"Tokenizer_100c3426467e__output"}}
